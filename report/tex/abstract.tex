\chapter*{Abstract}

\emph{Stencil} computations carried out on \emph{discrete grids} are a fundamental algorithmic motif in weather and climate models and are used to solve the governing differential equations of the atmosphere. These data-local calculations are easily parallelizable and are frequently implemented as GPU programs. Using \emph{unstructured grids} in such applications enables more flexible and fine-grained modeling than regular grids, but necessitates an additional level of indirection in the stencil implementation. In this thesis, we seek to quantify the cost of the \emph{indirect addressing} overhead and aim to minimize it through various optimizations.

We implement and benchmark three stencils, using the Nvidia \emph{CUDA} programming model, on regular and unstructured grids, and compare their runtimes. We explore five methods to access a grid's cells in a stencil code and test four strategies for storing the grid's structural information (neighborship table). Notably, we conceive a compression scheme for the neighborship table, which improves runtimes compared to uncompressed implementations by $30\%$ in some cases. Most of the other optimizations make use of an assumed regular structure in one of the dimensions, which is generally given in meteorology use cases.

We initially observe slowdowns of up to $2.07x$ for one stencil and improve this value to $1.45x$ with our optimizations. In one of the more complex stencils, indirect addressing leads to an overhead of only $1.04x$, which we cannot appreciably reduce. We observe that the effective use of caches is paramount to performance.

We gather that the overhead of using unstructured grids is minute for complicated stencils. In simple stencils, the relative slowdowns are larger but can be improved by several changes to the grid access and storage implementations.

% what & why
%  - physical models, weather, discretize
%  - solved on GPU
%  - move to unstructured -> challenges
%  - problem: cost of indirect addressing

% methods
%  - benchmarked three stencils
%  - several access implementations
%  - several storage implementations
%  - several sizes of grids

% key findings
%  - fist naive approaches: in some cases doubled runtime
%  - with optimizations: 
%      - slowdown 4% - 71%
%      - 4% for complex fastwaves stencil
%	   - 72% if we cannot control storage strategy in laplap
%	   - 45% if we can use compression etc
% - caching most important factor to get right

% conclusions
%  - optimizations useful
%  - overheads for complex stencils negligible
