\chapter{Related Work}

Implementing stencils on \emph{regular} grids using parallel architectures is a topic that has been extensively covered. The realization of frameworks for automatic stencil code generation and auto-tuning has seen special attention; examples include \cite{kamil2010auto}, \cite{christen2011patus}, and \cite{maruyama2011physis}. In \cite{gysi2015stella}, a domain-specific language for stencil applications on regular grids is presented alongside backends using \emph{OpenMP} (for CPU execution) and the \emph{CUDA} programming model (for execution on the GPU). The language is tested on the COSMO weather model \cite{cosmo}, achieving $1.8x$ (CPU) and $5.8x$ (GPU) speedups compared to the previous implementation. In the domain of computer graphics, \cite{ragan2013halide} introduces an optimizing compiler for the Halide image processing language. The Halide language enables the description of pipelines of stencils, and the compiler presented in the paper enables automatic synthetization of optimized and parallelized code across multiple platforms, including \emph{CUDA}.

Solano-Quinde et al. address the issue of implementing computations on \emph{unstructured} grids using a GPU architecture in their 2011 paper \cite{solano2011}. They present a general-purpose algorithm applicable for implementing scientific analyses in unstructured grids and name weather modeling as one of the possible use cases. They identify occupancy and memory access as the main limiting factors of performance. Their paper also explores the implications of using different memory layouts for the unstructured grid representation, concluding that \emph{struct-of-array-type} layouts are better suited for GPUs because of coalescing concerns. Contrary to our thesis, where one dimension remains regular (providing leeway for optimizations), a completely unstructured grid is assumed in their work. A $88\%$ speedup compared to CPU implementations is given, but no comparisons to regular grid implementations are drawn.

Following up in 2012, the same authors detail in \cite{solano2012} how further performance improvements can be attained in completely unstructured applications on multi-GPU systems, evaluating task- and data-parallel approaches for concurrent execution across multiple GPUs.

A comprehensive overview of the various methods of how unstructured grids for a problem domain can be generated is given by Mavriplis in \cite{mavriplis1997}. Section 3.4 of the publication also hints at how an unstructured grid may be stored in memory. In \cite{mavriplis2002parallel}, the same author details how a solver of Navier-Stokes equations can be implemented on an unstructured mesh, using the \emph{OpenMP} and \emph{MPI} parallelization techniques.

Addressing a broader set of algorithmic problems, Wang et al. \cite{wang2014} evaluate the performance implications of implementing several unstructured programs (including, for-example, breadth-first search and graph coloring) on the Nvidia \emph{CUDA} platform. In general, these problems include more complicated kernel code than stencil applications, but they share the same irregular memory access pattern as is associated with unstructured grid access. By detecting regular ``pockets of parallelism'', performance is improved. While $1.13x - 2.73x$ speedups compared to CPU implementations are attained for some problems, an average slowdown of $1.21x$ across all implementations is reported due to the added overheads.

A lot of research has been carried out concerning the compressed storage of meshes, such as in \cite{edgebreaker} and \cite{edgebreaker-quadrilateral}. However, most of those approaches are not usable in a stencil code, where decompression has to be virtually free and reordering of values is not permittable. However, the approach presented for compressing social network graphs in \cite{social} is relatively simple and similar to our evaluated compression approach in section \ref{sec:compression}.