\section{Overview of Results}

\begin{table}
	\begin{tabular}{l c c l c r} % c c}		
		\multicolumn{6}{c}{\textbf{Laplace-of-Laplace Stencil}} \\
		\hline
		\hline
		%& & & & \multicolumn{2}{c}{$512\times 512\times 64$ Grid} & \multicolumn{2}{c}{$128\times 128\times 64$ Grid} \\
		%\cline{5-6} %\cline{7-8} 
		Storage & (1) & (2) & Access Strategy  & Runtime & Slowdown \\ %& Runtime & Slowdown \\
		\hline 
		\multicolumn{3}{c}{regular grid baseline} & index variables & $353 \mu s$ & -\\
		\hline
		 row-major & \checkmark & \checkmark & index variables &  $\mathbf{512 \mu s}$ & $\mathbf{45 \%}$ \\
		 row-major & - & \checkmark & index variables & $515 \mu s$ & $46 \%$ \\
		 row-major & \checkmark & - & sliced z-loop & $582 \mu s$ & $65\%$ \\
		 row-major & - & - & sliced z-loop & $608 \mu s$ & $72 \%$ \\
		\hline
		 z-curves & - & \checkmark & naive & $\mathbf{528 \mu s}$ & $\mathbf{50 \%}$ \\
		 z-curves & \checkmark & \checkmark & index variables & $532 \mu s$ & $51 \%$ \\
		 z-curves & \checkmark & - &  z-loop & $546\mu s$ & $55 \%$ \\
		 z-curves & - & - & z-loop & $603 \mu s$ & $71 \%$ \\
		
		\hline
		\hline \\
		\multicolumn{6}{c}{\textbf{Horizontal Diffusion Stencil}} \\
		\hline
		\hline
		Storage & (1) & (2) & Access Strategy  & Runtime & Slowdown \\
		\hline
		\multicolumn{3}{c}{regular grid baseline} & index variables & $546 \mu s$ & - \\
		\hline
 		 row-major & - & \checkmark & naive & $\mathbf{683 \mu s}$ & $\mathbf{25 \%}$ \\
		
		 row-major & \checkmark & \checkmark & index variables & $731 \mu s$ & $34 \%$ \\
		
		 row-major & \checkmark & - & index variables & $804\mu s$ & $47\%$ \\
		 &   & &  shared (tie) & $804\mu s$ & $47\%$ \\
		 row-major & - & - & naive & $845 \mu s$ & $55 \%$ \\
		\hline
		 z-curves & - & \checkmark & naive & $\mathbf{710 \mu s}$ & $\mathbf{30 \%}$ \\
		 z-curves & \checkmark & \checkmark & index variables & $741 \mu s$ & $36 \%$ \\
		 z-curves & \checkmark & - & index variables & $820\mu s$ &  $50 \%$ \\
		 z-curves & - & - & shared & $841 \mu s$ & $54 \%$ \\
		
		\hline
		\hline\\
		\multicolumn{6}{c}{\textbf{Fastwaves Stencil}}\\
		\hline
		\hline
		Storage & (1) & (2) & Access Strategy  & Runtime & Slowdown \\
		\hline
		\multicolumn{3}{c}{regular grid baseline} & naive & $2298 \mu s$ & - \\
		\hline
		row-major & & - & naive & $\mathbf{2400\mu s}$ & $\mathbf{4.4 \%}$ \\
		row-major & & \checkmark & naive & $2433\mu s$ & $5.9 \%$ \\
		\hline
		z-curves & & - & naive & $\mathbf{2426\mu s}$ & $\mathbf{5.6 \%}$ \\
		z-curves & & \checkmark & naive & $2438\mu s$ & $6.1 \%$ \\
		\hline\hline
	\end{tabular}
	\begin{enumerate}[label=(\arabic*)]
		\item Pointer Chasing? (Checkmark if only direct neighbors are stored, no neighbors-of-neighbors, and pointer chasing occurs.)
		\item Compressed? (Checkmark if neighborship table was compressed.)
	\end{enumerate}
	\caption{\label{tab:overview} Fastest access strategy, runtimes (median of 20 runs) and relative slowdown given the grid storage type for the three benchmarked stencils on a $512\times 512\times 64$-sized grid of doubles.}
\end{table}

Table \ref{tab:overview} lists the fastest storage/access-combinations for all stencils and reports their runtimes and overhead. Across all executed benchmarks, we measured that the main cost of switching to an unstructured grid is a roughly a constant time penalty. On a $512\times 512\times 64$ grid, the additional time required by the unstructured kernels is between $137 \mu s$ and $159 \mu s$ for the fastest variants of the horizontal diffusion and Laplace-of-Laplace stencils. The latency in the computationally more complex fastwaves stencil is lower at $102 \mu s$ (in the best case), as it only accesses four neighbors. It is likely that the cost paid when switching to indirect addressing is mainly due to the latency of the neighborship table accesses which must occur before any computations can be done, and that these measured overheads quantify that latency.

The relative slowdowns are in the range of $4\%$ to $71\%$. The biggest differences in these relative slowdowns are observed due to differences between the stencils. As the overhead is largely constant, simpler stencils with less computation time spent per cell suffer more. For the most simple stencil, Laplace-of-Laplace (\emph{laplap}), relative slowdowns are largest with values of roughly $45\%$ to $71\%$. The more complex fastwaves stencil, which accesses nine different fields (compared to the one field of the \emph{laplap} stencil) only suffers from slowdowns in the $5\%$-area. The medium-intensity horizontal diffusion sits in the middle with its $25\% - 55\%$ range. 

In section \ref{sec:res-storage} and \ref{sec:res-access}, we explore the performance of the storage and access methods used. The chosen grid access strategy can have a high impact on the runtimes. Yet, no access strategy clearly dominates all others. Which implementation is fastest depends on the combination of access and storage, as well as on the stencil. Surprisingly, the \emph{naive} access strategy is competitive, and at times better than the optimized variations. The \emph{idxvar} optimization always performs similarly or slightly better. The optimized \emph{z-loop}, \emph{sliced z-loop} and the \emph{shared} access strategy did in most cases not pay off.

For both the horizontal diffusion and Laplace-of-Laplace stencils, compressing the neighborship table provides a significant benefit. However, due to the additional memory lookup required and unavoidable uncoalesced accesses to the compressed neighborship table, the advantage is not as large as one might at first expect.

Most results presented in this section focus on grids of size $512\times 512\times 64$. However, variations in the problem domain also lead to interesting observations. As the grids are still structured in the Z-dimension, changing the size of dimension and measuring the accompanying slowdowns reveals how the different implementations are able to make use of the regularity. In much smaller grids, the runtimes change in more hard-to-predict manners. At smaller sizes, the cache can be used more effectively. Generally, the relative slowdown in smaller grids also becomes smaller. Section \ref{sec:res-size} gives some insight into how the performance relates to the input domain size.

The choice of the right number of threads when launching the kernels is especially important. Depending on the implementation, a different number of threads, or a different arrangement of the threads is better. In section \ref{sec:res-blocksize} the effect of the block sizes is evaluated and explained.

\begin{verbatim}
% TODO 
% - Overview graph of only fastest variant per stencil
\end{verbatim}

